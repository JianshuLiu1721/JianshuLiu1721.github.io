[{"authors":["admin"],"categories":null,"content":"I am a tenure-track assistant professor in Department of Computer Science at Boise State University, leading the ‚≠ê Pisces Lab ‚≠ê. I received my Ph.D. degree in Computer Science from Louisiana State University in 2024, under the supervision of Dr. Qingyang Wang.\nMy interest lies in performance and scalability analysis of various cloud systems, with the aim of achieving good performance and high resource efficiency for evolving systems in cloud environments. My research relies on timeline analysis to investigate various factors that cause the performance variations of cloud systems. Moreover, we design and evaluate intelligent and automated frameworks to improve the system performance.\nMy collaborators are from Augusta University, Georgia Tech, Fujitsu Laboratories Ltd, etc. I have worked as a summer research intern at the University of Chicago, specifically in the Globus Labs.\nTo prospective students: I\u0026rsquo;m always looking for students who have a solid background in computer systems and share my research interests. If you are interested, please e-mail me with your Resume.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jianshuliu1721.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a tenure-track assistant professor in Department of Computer Science at Boise State University, leading the ‚≠ê Pisces Lab ‚≠ê. I received my Ph.D. degree in Computer Science from Louisiana State University in 2024, under the supervision of Dr. Qingyang Wang.\nMy interest lies in performance and scalability analysis of various cloud systems, with the aim of achieving good performance and high resource efficiency for evolving systems in cloud environments.","tags":null,"title":"Jianshu Liu ÂàòÈâ¥Â∫∂","type":"authors"},{"authors":["Zhiqi Li","Ruiqi Yu","__Jianshu Liu__"],"categories":[],"content":"","date":1740627067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740627067,"objectID":"7aae1057c7ced51e36c77ae486cfc075","permalink":"https://jianshuliu1721.github.io/publication/hotcloudperf25/","publishdate":"2025-02-26T22:31:07-05:00","relpermalink":"/publication/hotcloudperf25/","section":"publication","summary":"Recent advances in generative text-to-video AI models (e.g., VideoPoet and Sora) have spurred a surge in video production, leading to an increased demand for video processing pipelines among various video service providers such as YouTube and TikTok. With the improvement of cloud computing, video processing systems are frequently updated and present both opportunities and challenges while optimizing the quality of service (QoS) and cloud resource utilization. However, research on evaluating the performance of video processing systems is limited. Besides the availability of video datasets and realistic workloads, the lack of an open-source benchmark system reflecting the characteristics of industrial video processing systems is a significant gap. To fill this gap, we develop IrisBench, an open-source benchmark suite for cloud video processing systems to facilitate research on performance analysis. Our benchmark systems include three video services: video transcoding, video partitioning, and video object detection services. Our future work relies on using IrisBench to study the architectural implications of various cloud video processing systems in the cloud.","tags":[],"title":"IrisBench: An Open-Source Benchmark Suite for Video Processing Systems in Cloud","type":"publication"},{"authors":["Xuhang Gu","Qingyang Wang","__Jianshu Liu__","Jinpeng Wei"],"categories":[],"content":"","date":1711078267,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1711078267,"objectID":"5fbed5fba42d80d99254ea0239aa7b8d","permalink":"https://jianshuliu1721.github.io/publication/dsn24/","publishdate":"2024-03-21T22:31:07-05:00","relpermalink":"/publication/dsn24/","section":"publication","summary":"Loosely-coupled and lightweight microservices running in containers are likely to form complex execution dependencies inside the system. The execution dependency arises when two execution paths partially share component microservices, resulting in potential runtime blocking effects. In this paper, we present the Grunt Attack ‚Äì a novel low-volume DDoS attack that takes advantage of the execution dependencies of microservice applications. The Grunt Attack utilizes legitimate HTTP requests to accurately profile the internal pairwise dependencies of all supported execution paths in the target system. By grouping and characterizing all the execution paths based on their pairwise dependencies, a Grunt attacker can target only a few execution paths to launch a low-volume DDoS attack that achieves large performance damage to the entire system. To increase the attack stealthiness, the Grunt attacker avoids creating a persistent bottleneck by alternating the target execution paths within their dependency group.\n\nWe validate the effectiveness of Grunt attack through experiments of open-source microservices benchmark applications on real clouds (e.g., EC2, Azure) equipped with state-of-the-art IDS/IPS systems and live attack scenarios. Our results show that Grunt attack consumes less than 20% additional CPU resource of the target system while increasing its average response time by over 10x.","tags":[],"title":"Grunt Attack: Exploiting Execution Dependencies in Microservices","type":"publication"},{"authors":["Xuhang Gu","Qingyang Wang","Qiben Yan","__Jianshu Liu__","Calton Pu"],"categories":[],"content":"","date":1705375867,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705375867,"objectID":"5b6f99bc0ce9b1414c326a2b65412f71","permalink":"https://jianshuliu1721.github.io/publication/asiaccs24/","publishdate":"2024-01-05T22:31:07-05:00","relpermalink":"/publication/asiaccs24/","section":"publication","summary":"The modern web services landscape is characterized by numerous fine-grained, loosely coupled microservices with increasingly stringent low-latency requirements. However, this architecture also brings new performance vulnerabilities. In this paper, we introduce a novel low-volume application layer DDoS attack called the Sync-Millibottleneck (SyncM) attack, specifically targeting microservices. The goal of this attack is to cause a long-tail latency problem that violates the service-level agreement (SLA) for e-commerce while evading state-of-the-art DDoS detection/defense mechanisms. The SyncM attack exploits two unique features of microservices architecture: (1) the shared frontend gateway that directs user requests to mid-tier/backend microservices, and (2) the co-existence of multiple logically independent execution paths, each with its own bottleneck resource. By creating synchronized millibottlenecks (i.e., sub-second duration bottlenecks) on multiple independent execution paths, SyncM attack can cause the queuing effect in each execution path to be propagated along the path and superimposed in the shared frontend gateway microservice. As a result, SyncM triggers surprisingly high latency spikes in the system, even when all system resources are far from saturation, making it challenging to trace the cause of performance instability.\nTo evaluate the practicality of our attack, we conduct extensive experiments on real cloud systems such as EC2 and Azure, which are equipped with state-of-the-art IDS/IPS systems, under various workload scenarios. We also conduct a large-scale simulation using a production Alibaba trace to show the scalability of our attack. Our results demonstrate that the SyncM attack is highly effective, as it only consumes less than 15% of additional CPU resources of the target system while increasing its 95th percentile response time by more than 20 times.","tags":[],"title":"Sync-Millibottleneck Attack on Microservices Cloud Architecture","type":"publication"},{"authors":["__Jianshu Liu__","Shungeng Zhang","Qingyang Wang"],"categories":[],"content":"","date":1696563067,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696563067,"objectID":"5a7ecb70b65c3d4ef8e55fe23d7ec7d1","permalink":"https://jianshuliu1721.github.io/publication/socc23/","publishdate":"2023-10-05T22:31:07-05:00","relpermalink":"/publication/socc23/","section":"publication","summary":"Modern web-facing applications such as e-commerce comprise tens or hundreds of distributed and loosely coupled microservices that promise to facilitate high scalability. While hardware resource scaling approaches [28] have been proposed to address response time fluctuations in critical microservices, little attention has been given to the scaling of soft resources (e.g., threads or database connections), which control hardware resource concurrency. This paper demonstrates that optimal soft resource allocation for critical microservices significantly impacts overall system performance, particularly response time. This suggests the need for fast and intelligent runtime reallocation of soft resources as part of microservices scaling management. We introduce ùúáConAdapter, an intelligent and efficient framework for managing concurrency adaptation. It quickly identifies optimal soft resource allocations for critical microservices and adjusts them to mitigate violations of service-level objectives (SLOs). ùúáConAdapter utilizes fine-grained online monitoring metrics from both the system and application levels and a Deep Q-Network (DQN) to quickly and adaptively provide optimal concurrency settings for critical microservices. Using six realistic bursty workload traces and two representative microservices-based benchmarks (SockShop and SocialNetwork), our experimental results show that ùúáConAdapter can effectively mitigate large response time fluctuation and reduce the tail latency at the 99th percentile by 3√ó on average when compared to the hardware-only scaling strategies like Kubernetes Autoscaling and FIRM [28], and by 1.6√ó to the state-of-the-art concurrency-aware system scaling strategy like ConScale [21].","tags":[],"title":"ŒºConAdapter: Reinforcement Learning-based Fast Concurrency Adaptation for Microservices in Cloud","type":"publication"},{"authors":["Xuhang Gu","__Jianshu Liu__","Qingyang Wang"],"categories":[],"content":"","date":1696044667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696044667,"objectID":"f598d2e2d632ffc9f90968ecda6e99df","permalink":"https://jianshuliu1721.github.io/publication/cic23/","publishdate":"2023-10-02T22:31:07-05:00","relpermalink":"/publication/cic23/","section":"publication","summary":"Loosely-coupled and lightweight microservices running in containers are likely to form complex execution dependencies inside the system. The execution dependency arises when two execution paths partially share component microservices, resulting in potential runtime performance interference. In this paper, we present a blackbox approach that utilizes legitimate HTTP requests to accurately profile the internal pairwise dependencies of all supported execution paths in the target microservices application. Concretely, we profile the pairwise dependency of two execution paths through performance interference analysis by sending bursts of two types of requests simultaneously. By characterizing and grouping all the execution paths based on their pairwise dependencies, the blackbox approach can derive a clear dependency graph(s) of the entire backend of the microservices application. We validate the effectiveness of the blackbox approach through experiments of open-source microservices benchmark applications running on real clouds (e.g., EC2, Azure).","tags":[],"title":"A BlackBox Approach to Profile Runtime Execution Dependencies in Microservices","type":"publication"},{"authors":["__Jianshu Liu__","Qingyang Wang","Shungeng Zhang","Liting Hu","and Dilma Da Silva"],"categories":[],"content":"","date":1675740667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1675740667,"objectID":"74d714bad37f41ed1b9ac82f32f08f07","permalink":"https://jianshuliu1721.github.io/publication/middleware23/","publishdate":"2023-02-08T22:31:07-05:00","relpermalink":"/publication/middleware23/","section":"publication","summary":"Fast response time for modern web services that include numerous distributed and lightweight microservices becomes increasingly important due to its business impact. While hardware-only resource scaling approaches (e.g., FIRM [47] and PARSLO [40]) have been proposed to mitigate response time fluctuations on critical microservices, the re-adaptation of soft resources (e.g., threads or connections) that control the concurrency of hardware resource usage has been largely ignored. This paper shows that the soft resource adaptation of critical microservices has a significant impact on system scalability because either under- or over-allocation of soft resources can lead to inefficient usage of underlying hardware resources. We present Sora, an intelligent, fast soft resource adaptation management framework for quickly identifying and adjusting the optimal concurrency level of critical microservices to mitigate service-level objective (SLO) violations. Sora leverages online finegrained system metrics and the propagated deadline along the critical path of request execution to quickly and accurately provide optimal concurrency setting for critical microservices. Based on six real-world bursty workload traces and two representative microservices benchmarks (Sock Shop and Social Network), our experimental results show that Sora can effectively mitigate large response time fluctuations and reduce the 99th percentile latency by up to 2.5√ó compared to the hardware-only scaling strategy FIRM [47] and 1.5√ó to the state-of-the-art concurrency-aware system scaling strategy ConScale.","tags":[],"title":"Sora: A Latency Sensitive Approach for Microservice Soft Resource Adaptation","type":"publication"},{"authors":["Shungeng Zhang","Qingyang Wang","Yasuhiko Kanemasa","Julius Michaelis","__Jianshu Liu__","and Calton Pu"],"categories":[],"content":"","date":1667964667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667964667,"objectID":"9bb1b486ab9233458b94c50ac74b0e85","permalink":"https://jianshuliu1721.github.io/publication/middleware22/","publishdate":"2022-11-08T22:31:07-05:00","relpermalink":"/publication/middleware22/","section":"publication","summary":"Mission-critical, real-time, continuous stream processing applications that interact with the real world have stringent latency requirements. For example, e-commerce websites like Amazon improve their marketing strategy by performing real-time advertising based on customers‚Äô behavior, and latency long tail can cause signicant revenue loss. Recent work [39] showed a positive correlation between latency long tail and variance in the execution time of synchronous invocation chains (critical paths) in microservices benchmarks. This paper shows that asynchronous, very short but intense resource demands (called millibottlenecks) outside of critical paths can also cause significant latency long tail.\nUsing a trace analysis stream processing application benchmark, we evaluated the impact of asynchronous workload bursts generated by a multi-layer data structure called LSM-tree (logstructured merge-tree) for continuous checkpointing. Outside of the critical path, LSM-tree relies on maintenance operations (e.g.,flushing/compaction during a checkpoint) to reorganize LSM-tree in memory and on disk to keep data access latency short. Although asynchronous, such recurrent maintenance operations can cause frequent millibottlenecks, particularly when they overlap, a problem we call ShadowSync. For scheduling and statistical reasons, significant latency long tail can arise from ShadowSync caused by asynchronous recurrent operations. Our experimental results show that with typical settings of benchmark components such as RocksDB, ShadowSync can prolong request message latency by up to 2 seconds. We show effective mitigation methods can alleviate both scheduled and statistical ShadowSync reducing the latency long tail to less than 20% of the original at the 99.9th percentile.","tags":[],"title":"ShadowSync: Latency Long Tail caused by Hidden Synchronization in Real-time LSM-tree based Stream Processing Systems","type":"publication"},{"authors":["__Jianshu Liu__","Shungeng Zhang","Qingyang Wang","and Jinpeng Wei"],"categories":[],"content":"","date":1644898516,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644898516,"objectID":"5d89b7920b41c914486c8c11f397e8ed","permalink":"https://jianshuliu1721.github.io/publication/tpds22/","publishdate":"2022-02-14T22:15:16-06:00","relpermalink":"/publication/tpds22/","section":"publication","summary":"Cloud providers tend to support dynamic computing resources reallocation (e.g., Autoscaling) to handle the bursty workload for web applications (e.g., e-commerce) in the cloud environment. Nevertheless, we demonstrate that directly scaling a bottleneck server without quickly adjusting its soft resources (e.g., server threads and database connections) can cause significant response time fluctuations of the target web application. Since soft resources determine the request processing concurrency of each server in the system, simply scaling out/in the bottleneck service can unintentionally change the concurrency level of related services, inducing either under- or over-utilization of the critical hardware resource. In this paper, we propose the Scatter-Concurrency-Throughput (SCT) model, which can rapidly identify the near-optimal soft resource allocation of each server in the system using the measurement of each server's real-time throughput and concurrency. Furthermore, we implement a Concurrency-aware autoScaling (ConScale) framework that integrates the SCT model to quickly reallocate the soft resources of the key servers in the system to best utilize the new hardware resource capacity after the system scaling. Based on extensive experimental comparisons with two widely used hardware-only scaling mechanisms for web applications: EC2-AutoScaling (VM-based autoscaler) and Kubernetes HPA (container-based autoscaler), we show that ConScale can successfully mitigate the response time fluctuations over the system scaling phase in both VM-based and container-based environments.","tags":[],"title":"Coordinating Fast Concurrency Adapting with Autoscaling for SLO-Oriented Web Applications","type":"publication"},{"authors":["Calton Pu","Qingyang Wang","Yasuhiko Kanemasa","Rodrigo Alves Lima","Joshua Kimball","Shungeng Zhang","__Jianshu Liu__","Xuhang Gu"],"categories":[],"content":"","date":1639452667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639452667,"objectID":"3b7228ad159c4ce2e853089dd5cfbe3a","permalink":"https://jianshuliu1721.github.io/publication/tps-isa21/","publishdate":"2022-04-14T22:31:07-05:00","relpermalink":"/publication/tps-isa21/","section":"publication","summary":"Recent ransomware attacks (e.g., Colonial and JBS) caused significant social and economic impact due to their ability to shut down entire businesses. A functional model divides nextgeneration malware (NG-malware) attacks into 3 stages: Penetration (to gain a foothold), Propagation (to gain full control of target system), and a variety of Exploitation methods. The functional model shows that many attack methods and tools can be flexibly combined to bypass implementation-specific defenses at each stage, with the most important defense battleground being the prevention of NG-malware gaining full control of target system. Given the potential for further evolution of MG-malware, e.g., obfuscation of lateral movement jobs to increase both the speed and stealth of Propagation, it is crucial for the defense to develop effective defenses to detect NG-malware Propagation before ceding full control. An experimental platform that enables detailed evaluation of new NG-malware attacks and defenses is an effective tool in the battle for full control.","tags":[],"title":"A Functional Model and Analysis of Next Generation Malware Attacks and Defenses","type":"publication"},{"authors":["Shungeng Zhang","Qingyang Wang","Yasuhiko Kanemasa","__Jianshu Liu__","and Calton Pu"],"categories":[],"content":"","date":1599017467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599017467,"objectID":"45f074fc5620c025fac68a92c23a43a7","permalink":"https://jianshuliu1721.github.io/publication/middleware20/","publishdate":"2020-09-01T22:31:07-05:00","relpermalink":"/publication/middleware20/","section":"publication","summary":"The broad adoption of fanout queries on distributed datastores has made asynchronous event-driven datastore drivers a natural choice due to reduced multithreading overhead. However, through extensive experiments using the latest datastore drivers (e.g., MongoDB, HBase, DynamoDB) and YCSB benchmark, we show that an asynchronous datastore driver can cause unexpected performance degradation especially in fanout-query scenarios. For example, the default MongoDB asynchronous driver adopts the latest Java asynchronous I/O library, which uses a hidden on-demand JVM level thread pool to process fanout query responses, causing a surprising multithreading overhead when the query response size is large. A second instance is the traditional wisdom of modular design of an application server and the embedded asynchronous datastore driver can cause an imbalanced workload between the two components due to lack of coordination, incurring frequent unnecessary system calls. To address the revealed problems, we introduce DoubleFaceAD‚Äìa new asynchronous datastore driver architecture that integrates the management of both upstream and downstream workload traffic through a few shared reactor threads, with a fanout-query-aware priority-based scheduling to reduce the overall query waiting time. Our experimental results on three representative application scenarios (YCSB, DBLP, and microservices) show DoubleFaceAD outperforms all other types of datastore drivers up to 34% on throughput and 2.5√ó faster on 95th percentile response time.","tags":[],"title":"DoubleFaceAD:A New Datastore Drive Architecture to Optimize Fanout Query Performance","type":"publication"},{"authors":["__Jianshu Liu__","Shungeng Zhang","Qingyang Wang","and Jinpeng Wei"],"categories":[],"content":"","date":1589595976,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589595976,"objectID":"23b2afbcfc0f8382893594807c1aa780","permalink":"https://jianshuliu1721.github.io/publication/ipdps20/","publishdate":"2020-05-15T22:15:16-06:00","relpermalink":"/publication/ipdps20/","section":"publication","summary":"Dynamically reallocating computing resources to handle bursty workloads is a common practice for web applications (e.g., e-commerce) in clouds. However, our empirical analysis on a standard n-tier benchmark application (RUBBoS) shows that simply scaling an n-tier application by reallocating hardware resources without fast adapting soft resources (e.g., server threads, connections) may lead to large response time fluctuations. This is because soft resources control the workload concurrency of component servers in the system: adding or removing hardware resources such as Virtual Machines (VMs) can implicitly change the workload concurrency of dependent servers, causing either under- or over-utilization of the critical hardware resource in the system. To quickly identify the optimal soft resource allocation of each server in the system and stabilize response time fluctuation, we propose a novel ScatterConcurrency-Throughput (SCT) model based on the monitoring of each server‚Äôs real-time concurrency and throughput. We then implement a Concurrency-aware system Scaling (ConScale) framework which integrates the SCT model to fast adapt the soft resource allocations of key servers during the system scaling process. Our experiments using six realistic bursty workload traces show that ConScale can effectively mitigate the response time fluctuations of the target web application compared to the state-of-the-art cloud scaling strategies such as EC2-AutoScaling.","tags":[],"title":"Mitigating Large Response Time Fluctuations through Fast Concurrency Adapting in Clouds","type":"publication"},{"authors":["Shungeng Zhang","Huasong Shan","Qingyang Wang","__Jianshu Liu__","Qiben Yan","and Jinpeng Wei"],"categories":[],"content":"","date":1562816299,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562816299,"objectID":"60ef6f602e382a7754abadbf72cf90ea","permalink":"https://jianshuliu1721.github.io/publication/icdcs19/","publishdate":"2019-07-10T21:38:19-06:00","relpermalink":"/publication/icdcs19/","section":"publication","summary":"Fast response time becomes increasingly important for modern web applications (e.g., e-commerce) due to intense competitive pressure. In this paper, we present a new type of Denial of Service (DoS) Attacks in the cloud, MemCA, with the goal of causing performance uncertainty (the long-tail response time problem) of the target n-tier web application while keeping stealthy. MemCA exploits the sharing nature of public cloud computing platforms by co-locating the adversary VMs with the target VMs that host the target web application, and causing intermittent and short-lived cross-resource contentions on the target VMs. We show that these short-lived cross-resource contentions can cause transient performance interferences that lead to large response time fluctuations of the target web application, due to complex resource dependencies in the system. We further model the attack scenario in n-tier systems based on queuing network theory, and analyze cross-tier queue overflow and tail response time amplification under our attacks. Through extensive benchmark experiments in both private and public clouds (e.g., Amazon EC2), we confirm that MemCA can cause significant performance uncertainty of the target n-tier system while keeping stealthy. Specifically, we show that MemCA not only bypasses the cloud elastic scaling mechanisms, but also the state-of-the-art cloud performance interference detection mechanisms.","tags":[],"title":"Tail Amplification in n-Tier Systems: A Study of Transient Cross-Resource Contention Attacks","type":"publication"}]